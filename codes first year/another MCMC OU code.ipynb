{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import decimal\n",
    "import scipy.linalg\n",
    "import numpy.random as nrand\n",
    "import matplotlib.pyplot as plt\n",
    "import gpflow\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 6)\n",
    "plt = matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ou_values(a,b,dt,sigma,time):\n",
    "    #This method returns the rate levels of a mean-reverting ornstein uhlenbeck process.\n",
    "    x = np.zeros(len(time))\n",
    "    for i in range(0, len(time)-1):\n",
    "        x[i+1]=x[i]+a*(b-x[i])*dt+math.sqrt(dt)*sigma*np.random.normal(0,1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=0.002\n",
    "time=np.arange(0,5,dt)# time\n",
    "sigma=2\n",
    "a=1# the coefficient in front, the rate\n",
    "b=0# the mean\n",
    "#Simulation of an OU process\n",
    "x=ou_values(a,b,dt,sigma,time)# the first one is zero because param_all_r0 starts at 0\n",
    "t=time# time vector\n",
    "plt.plot(t,x)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('OU process')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_column=t.reshape(-1,1)\n",
    "x_column=x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=gpflow.kernels.Matern12(1, lengthscales=0.3)\n",
    "meanf = gpflow.mean_functions.Linear(1.0, 0.0)\n",
    "m = gpflow.models.GPR(t_column,x_column, k, meanf)\n",
    "m.likelihood.variance = 0.1# get this to be bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.clear()\n",
    "m.kern.lengthscales.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m.kern.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m.likelihood.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m.mean_function.A.prior = gpflow.priors.Gaussian(0., 10.)\n",
    "m.mean_function.b.prior = gpflow.priors.Gaussian(0., 10.)\n",
    "m.compile()\n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1=gpflow.kernels.Matern12(1, lengthscales=5,variance=5)\n",
    "meanf1 = gpflow.mean_functions.Linear(5.0, 10.0)\n",
    "m1 = gpflow.models.GPR(t_column,x_column, k1, meanf1)\n",
    "m1.likelihood.variance = 1# get this to be bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.clear()\n",
    "m1.kern.lengthscales.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m1.kern.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m1.likelihood.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m1.mean_function.A.prior = gpflow.priors.Gaussian(0., 10.)\n",
    "m1.mean_function.b.prior = gpflow.priors.Gaussian(0., 10.)\n",
    "m1.compile()\n",
    "m1.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2=gpflow.kernels.Matern12(1, lengthscales=20,variance=10)\n",
    "meanf2 = gpflow.mean_functions.Linear(10.0, 5.0)\n",
    "m2 = gpflow.models.GPR(t_column,x_column, k2, meanf2)\n",
    "m2.likelihood.variance = 2# get this to be bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.clear()\n",
    "m2.kern.lengthscales.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m2.kern.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m2.likelihood.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m2.mean_function.A.prior = gpflow.priors.Gaussian(0., 10.)\n",
    "m2.mean_function.b.prior = gpflow.priors.Gaussian(0., 10.)\n",
    "m2.compile()\n",
    "m2.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = gpflow.train.HMC()\n",
    "samples = sampler.sample(m, num_samples=gpflow.test_util.notebook_niter(10000), epsilon=0.05,logprobs=False)#,lmin=10, lmax=20, logprobs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "for i, col in samples.iteritems():\n",
    "    plt.plot(col, label=col.name)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('hmc iteration')\n",
    "plt.ylabel('parameter value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "axs[0].plot(samples['GPR/likelihood/variance'],\n",
    "            samples['GPR/kern/variance'], 'k.', alpha = 0.15)\n",
    "axs[0].set_xlabel('noise_variance')\n",
    "axs[0].set_ylabel('signal_variance')\n",
    "\n",
    "axs[1].plot(samples['GPR/likelihood/variance'],\n",
    "            samples['GPR/kern/lengthscales'], 'k.', alpha = 0.15)\n",
    "axs[1].set_xlabel('noise_variance')\n",
    "axs[1].set_ylabel('lengthscale')\n",
    "\n",
    "axs[2].plot(samples['GPR/kern/lengthscales'],\n",
    "            samples['GPR/kern/variance'], 'k.', alpha = 0.1)\n",
    "axs[2].set_xlabel('lengthscale')\n",
    "axs[2].set_ylabel('signal_variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the function posterior\n",
    "xx = np.linspace(0, 6, 100)[:,None]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, s in samples.iloc[::20].iterrows():\n",
    "    f = m.predict_f_samples(xx, 1, initialize=False, feed_dict=m.sample_feed_dict(s))\n",
    "    plt.plot(xx, f[0,:,:], 'C0', lw=2, alpha=0.1)\n",
    "    \n",
    "plt.plot(t, x, 'kx', mew=2)\n",
    "_ = plt.xlim(xx.min(), xx.max())\n",
    "_ = plt.ylim(-10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler1 = gpflow.train.HMC()\n",
    "samples1 = sampler1.sample(m1, num_samples=gpflow.test_util.notebook_niter(100000), epsilon=0.05,logprobs=False)#,lmin=10, lmax=20, logprobs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "for i, col in samples1.iteritems():\n",
    "    plt.plot(col, label=col.name)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('hmc iteration')\n",
    "plt.ylabel('parameter value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "axs[0].plot(samples1['GPR/likelihood/variance'],\n",
    "            samples1['GPR/kern/variance'], 'k.', alpha = 0.15)\n",
    "axs[0].set_xlabel('noise_variance')\n",
    "axs[0].set_ylabel('signal_variance')\n",
    "\n",
    "axs[1].plot(samples1['GPR/likelihood/variance'],\n",
    "            samples1['GPR/kern/lengthscales'], 'k.', alpha = 0.15)\n",
    "axs[1].set_xlabel('noise_variance')\n",
    "axs[1].set_ylabel('lengthscale')\n",
    "\n",
    "axs[2].plot(samples1['GPR/kern/lengthscales'],\n",
    "            samples1['GPR/kern/variance'], 'k.', alpha = 0.1)\n",
    "axs[2].set_xlabel('lengthscale')\n",
    "axs[2].set_ylabel('signal_variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the function posterior\n",
    "xx = np.linspace(0, 6, 100)[:,None]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, s in samples1.iloc[::20].iterrows():\n",
    "    f = m1.predict_f_samples(xx, 1, initialize=False, feed_dict=m1.sample_feed_dict(s))\n",
    "    plt.plot(xx, f[0,:,:], 'C0', lw=2, alpha=0.1)\n",
    "    \n",
    "plt.plot(t, x, 'kx', mew=2)\n",
    "_ = plt.xlim(xx.min(), xx.max())\n",
    "_ = plt.ylim(-8, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler2 = gpflow.train.HMC()\n",
    "samples2 = sampler2.sample(m2, num_samples=gpflow.test_util.notebook_niter(100000), epsilon=0.05,logprobs=False)#,lmin=10, lmax=20, logprobs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "for i,col in samples2.iteritems():\n",
    "    plt.plot(col, label=col.name)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('hmc iteration')\n",
    "plt.ylabel('parameter value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "axs[0].plot(samples2['GPR/likelihood/variance'],\n",
    "            samples2['GPR/kern/variance'], 'k.', alpha = 0.15)\n",
    "axs[0].set_xlabel('noise_variance')\n",
    "axs[0].set_ylabel('signal_variance')\n",
    "\n",
    "axs[1].plot(samples2['GPR/likelihood/variance'],\n",
    "            samples2['GPR/kern/lengthscales'], 'k.', alpha = 0.15)\n",
    "axs[1].set_xlabel('noise_variance')\n",
    "axs[1].set_ylabel('lengthscale')\n",
    "\n",
    "axs[2].plot(samples2['GPR/kern/lengthscales'],\n",
    "            samples2['GPR/kern/variance'], 'k.', alpha = 0.1)\n",
    "axs[2].set_xlabel('lengthscale')\n",
    "axs[2].set_ylabel('signal_variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the function posterior\n",
    "xx = np.linspace(0, 6, 100)[:,None]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, s in samples2.iloc[::20].iterrows():\n",
    "    f = m2.predict_f_samples(xx, 1, initialize=False, feed_dict=m2.sample_feed_dict(s))\n",
    "    plt.plot(xx, f[0,:,:], 'C0', lw=2, alpha=0.1)\n",
    "    \n",
    "plt.plot(t, x, 'kx', mew=2)\n",
    "_ = plt.xlim(xx.min(), xx.max())\n",
    "_ = plt.ylim(-10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gelman-Rubin Statistic calculated for the three parameters +2 meanf parameters\n",
    "#first chain\n",
    "variance_vector=samples['GPR/kern/variance'].values# works works works !!!!\n",
    "lengthscales_vector=samples['GPR/kern/lengthscales'].values\n",
    "likelihood_variance_vector=samples['GPR/likelihood/variance'].values\n",
    "mean_A=samples['GPR/mean_function/A'].values\n",
    "mean_B=samples['GPR/mean_function/b'].values\n",
    "\n",
    "\n",
    "#second chain\n",
    "variance_vector1=samples1['GPR/kern/variance'].values# works works works !!!!\n",
    "lengthscales_vector1=samples1['GPR/kern/lengthscales'].values\n",
    "likelihood_variance_vector1=samples1['GPR/likelihood/variance'].values\n",
    "mean_A1=samples1['GPR/mean_function/A'].values\n",
    "mean_B1=samples1['GPR/mean_function/b'].values\n",
    "\n",
    "# third chain\n",
    "variance_vector2=samples2['GPR/kern/variance'].values# works works works !!!!\n",
    "lengthscales_vector2=samples2['GPR/kern/lengthscales'].values\n",
    "likelihood_variance_vector2=samples2['GPR/likelihood/variance'].values\n",
    "mean_A2=samples2['GPR/mean_function/A'].values\n",
    "mean_B2=samples2['GPR/mean_function/b'].values\n",
    "\n",
    "\n",
    "# create a list with all the three chains wrt each parameter in turn +2 mean parameters\n",
    "l_variance=[]\n",
    "l_lengthscales=[]\n",
    "l_likelihood_variance=[]\n",
    "l_meanA=[]\n",
    "l_meanB=[]\n",
    "# append the vectors\n",
    "#variance_vectors\n",
    "l_variance.append(variance_vector)\n",
    "l_variance.append(variance_vector1)\n",
    "l_variance.append(variance_vector2)\n",
    "#lengthscales_vectors\n",
    "l_lengthscales.append(lengthscales_vector)\n",
    "l_lengthscales.append(lengthscales_vector1)\n",
    "l_lengthscales.append(lengthscales_vector2)\n",
    "#likelihood_variance_vectors\n",
    "l_likelihood_variance.append(likelihood_variance_vector)\n",
    "l_likelihood_variance.append(likelihood_variance_vector1)\n",
    "l_likelihood_variance.append(likelihood_variance_vector2)\n",
    "#meanA vectors\n",
    "l_meanA.append(mean_A)\n",
    "l_meanA.append(mean_A1)\n",
    "l_meanA.append(mean_A2)\n",
    "#meanB vectors\n",
    "l_meanB.append(mean_B)\n",
    "l_meanB.append(mean_B1)\n",
    "l_meanB.append(mean_B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x: data cell array\n",
    "# m: no of chains run\n",
    "# Within Chain Variance \n",
    "m=3\n",
    "ssq_variance = np.zeros(m)\n",
    "ssq_lengthscales=np.zeros(m)\n",
    "ssq_likelihood_variance=np.zeros(m)\n",
    "ssq_meanA=np.zeros(m)\n",
    "ssq_meanB=np.zeros(m)\n",
    "\n",
    "for j in range(0,m):\n",
    "    ssq_variance[j]=np.var(l_variance[j])\n",
    "    ssq_lengthscales[j]=np.var(l_lengthscales[j])    \n",
    "    ssq_likelihood_variance[j]=np.var(l_likelihood_variance[j])    \n",
    "    ssq_meanA[j]=np.var(l_meanA[j])    \n",
    "    ssq_meanB[j]=np.var(l_meanB[j])    \n",
    "                        \n",
    "    \n",
    "Wvar_variance = np.mean(ssq_variance)\n",
    "Wvar_lengthscales=np.mean(ssq_lengthscales)\n",
    "Wvar_likelihood_variance=np.mean(ssq_likelihood_variance)\n",
    "Wvar_meanA = np.mean(ssq_meanA)\n",
    "Wvar_meanB = np.mean(ssq_meanB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Between Chain Variance\n",
    "schain_variance,schain_lengthscales,schain_likelihood_variance,schain_meanA,schain_meanB = 0,0,0,0,0\n",
    "chainlng_variance=len(l_variance[0])\n",
    "chainlng_lengthscales=len(l_lengthscales[0])\n",
    "chainlng_likelihood_variance=len(l_likelihood_variance[0])\n",
    "chainlng_meanA=len(l_meanA[0])\n",
    "chainlng_meanB=len(l_meanB[0])\n",
    "\n",
    "for j in range(0,m):\n",
    "    schain_variance = schain_variance + np.mean(l_variance[j]) # sum of all chain means\n",
    "    schain_lengthscales = schain_lengthscales + np.mean(l_lengthscales[j])\n",
    "    schain_likelihood_variance = schain_likelihood_variance+np.mean(l_likelihood_variance[j])\n",
    "    schain_meanA = schain_meanA + np.mean(l_meanA[j]) # sum of all chain means\n",
    "    schain_meanB = schain_meanB + np.mean(l_meanB[j]) # sum of all chain means\n",
    "\n",
    "mubar2_variance = (1/m) * schain_variance\n",
    "mubar2_lengthscales = (1/m) * schain_lengthscales\n",
    "mubar2_likelihood_variance = (1/m) * schain_likelihood_variance\n",
    "mubar2_meanA = (1/m) * schain_meanA\n",
    "mubar2_meanB = (1/m) * schain_meanB\n",
    "\n",
    "\n",
    "bs_variance,bs_lengthscales,bs_likelihood_variance,bs_meanA,bs_meanB=0,0,0,0,0\n",
    "\n",
    "for j in range(0,m):\n",
    "    bs_variance=bs_variance + (np.mean(l_variance[j])-mubar2_variance)**2\n",
    "    bs_lengthscales=bs_lengthscales + (np.mean(l_lengthscales[j])-mubar2_lengthscales)**2\n",
    "    bs_likelihood_variance=bs_likelihood_variance + np.mean(l_likelihood_variance[j]-mubar2_likelihood_variance )**2\n",
    "    bs_meanA=bs_meanA + (np.mean(l_meanA[j])-mubar2_meanA)**2\n",
    "    bs_meanB=bs_variance + (np.mean(l_meanB[j])-mubar2_meanB)**2\n",
    "\n",
    "Bvar_variance = (chainlng_variance/(m-1)) * bs_variance # all chains have the same length\n",
    "Bvar_lengthscales = (chainlng_lengthscales/(m-1)) * bs_lengthscales\n",
    "Bvar_likelihood_variance = (chainlng_likelihood_variance/(m-1)) * bs_likelihood_variance\n",
    "Bvar_meanA = (chainlng_meanA/(m-1)) * bs_meanA # all chains have the same length\n",
    "Bvar_meanB = (chainlng_meanB/(m-1)) * bs_meanB # all chains have the same length\n",
    "\n",
    "# Estimated variance\n",
    "muvar_variance = (1-1/chainlng_variance) * Wvar_variance + (1/chainlng_variance)*Bvar_variance\n",
    "muvar_lengthscales = (1-1/chainlng_lengthscales) * Wvar_lengthscales+ (1/chainlng_lengthscales)*Bvar_lengthscales\n",
    "muvar_likelihood_variance = (1-1/chainlng_likelihood_variance) * Wvar_likelihood_variance + (1/chainlng_likelihood_variance) * Bvar_likelihood_variance\n",
    "muvar_meanA = (1-1/chainlng_meanA) * Wvar_meanA + (1/chainlng_meanA)*Bvar_meanA\n",
    "muvar_meanB = (1-1/chainlng_meanB) * Wvar_meanB + (1/chainlng_meanB)*Bvar_meanB\n",
    "\n",
    "# Potential Scale Reduction Factor\n",
    "R_variance = np.sqrt(muvar_variance/Wvar_variance)\n",
    "R_lengthscales = np.sqrt(muvar_lengthscales/Wvar_lengthscales) \n",
    "R_likelihood_variance = np.sqrt(muvar_likelihood_variance/Wvar_likelihood_variance) \n",
    "R_meanA = np.sqrt(muvar_meanA/Wvar_meanA)\n",
    "R_meanB = np.sqrt(muvar_meanB/Wvar_meanB)\n",
    "\n",
    "print(R_variance)\n",
    "print(R_lengthscales)# smaller than 1.1, so the chain has converged.\n",
    "print(R_likelihood_variance)# smaller than 1.1, so the chain has converged.\n",
    "print(R_meanA)\n",
    "print(R_meanB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# another try without adding the meanf\n",
    "t_column=t.reshape(-1,1)\n",
    "x_column=x.reshape(-1,1)\n",
    "k=gpflow.kernels.Matern12(1, lengthscales=10)\n",
    "m = gpflow.models.GPR(t_column,x_column, k)\n",
    "m.likelihood.variance = 0.1\n",
    "m.kern.variance=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.clear()\n",
    "m.kern.lengthscales.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m.kern.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m.likelihood.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m.compile()\n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k1=gpflow.kernels.Matern12(1, lengthscales=5,variance=5)\n",
    "m1 = gpflow.models.GPR(t_column,x_column, k1)\n",
    "m1.likelihood.variance = 1# get this to be bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1.clear()\n",
    "m1.kern.lengthscales.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m1.kern.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m1.likelihood.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m1.compile()\n",
    "m1.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k2=gpflow.kernels.Matern12(1, lengthscales=20,variance=10)\n",
    "m2 = gpflow.models.GPR(t_column,x_column, k2)\n",
    "m2.likelihood.variance = 2# get this to be bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m2.clear()\n",
    "m2.kern.lengthscales.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m2.kern.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m2.likelihood.variance.prior = gpflow.priors.Gamma(1., 1.)\n",
    "m2.compile()\n",
    "m2.as_pandas_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = gpflow.train.HMC()\n",
    "samples = sampler.sample(m, num_samples=gpflow.test_util.notebook_niter(100000), epsilon=0.05,logprobs=False)#,lmin=10, lmax=20, logprobs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "for i, col in samples.iteritems():\n",
    "    plt.plot(col, label=col.name)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('hmc iteration')\n",
    "plt.ylabel('parameter value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "axs[0].plot(samples['GPR/likelihood/variance'],\n",
    "            samples['GPR/kern/variance'], 'k.', alpha = 0.15)\n",
    "axs[0].set_xlabel('noise_variance')\n",
    "axs[0].set_ylabel('signal_variance')\n",
    "\n",
    "axs[1].plot(samples['GPR/likelihood/variance'],\n",
    "            samples['GPR/kern/lengthscales'], 'k.', alpha = 0.15)\n",
    "axs[1].set_xlabel('noise_variance')\n",
    "axs[1].set_ylabel('lengthscale')\n",
    "\n",
    "axs[2].plot(samples['GPR/kern/lengthscales'],\n",
    "            samples['GPR/kern/variance'], 'k.', alpha = 0.1)\n",
    "axs[2].set_xlabel('lengthscale')\n",
    "axs[2].set_ylabel('signal_variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the function posterior\n",
    "xx = np.linspace(0, 6, 100)[:,None]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, s in samples.iloc[::20].iterrows():\n",
    "    f = m.predict_f_samples(xx, 1, initialize=False, feed_dict=m.sample_feed_dict(s))\n",
    "    plt.plot(xx, f[0,:,:], 'C0', lw=2, alpha=0.1)\n",
    "    \n",
    "plt.plot(t, x, 'kx', mew=2)\n",
    "_ = plt.xlim(xx.min(), xx.max())\n",
    "_ = plt.ylim(-8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler1 = gpflow.train.HMC()\n",
    "samples1 = sampler1.sample(m1, num_samples=gpflow.test_util.notebook_niter(100000), epsilon=0.05,logprobs=False)#,lmin=10, lmax=20, logprobs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "for i, col in samples1.iteritems():\n",
    "    plt.plot(col, label=col.name)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('hmc iteration')\n",
    "plt.ylabel('parameter value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "axs[0].plot(samples1['GPR/likelihood/variance'],\n",
    "            samples1['GPR/kern/variance'], 'k.', alpha = 0.15)\n",
    "axs[0].set_xlabel('noise_variance')\n",
    "axs[0].set_ylabel('signal_variance')\n",
    "\n",
    "axs[1].plot(samples1['GPR/likelihood/variance'],\n",
    "            samples1['GPR/kern/lengthscales'], 'k.', alpha = 0.15)\n",
    "axs[1].set_xlabel('noise_variance')\n",
    "axs[1].set_ylabel('lengthscale')\n",
    "\n",
    "axs[2].plot(samples1['GPR/kern/lengthscales'],\n",
    "            samples1['GPR/kern/variance'], 'k.', alpha = 0.1)\n",
    "axs[2].set_xlabel('lengthscale')\n",
    "axs[2].set_ylabel('signal_variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the function posterior\n",
    "xx = np.linspace(0, 6, 100)[:,None]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, s in samples1.iloc[::20].iterrows():\n",
    "    f = m1.predict_f_samples(xx, 1, initialize=False, feed_dict=m1.sample_feed_dict(s))\n",
    "    plt.plot(xx, f[0,:,:], 'C0', lw=2, alpha=0.1)\n",
    "    \n",
    "plt.plot(t, x, 'kx', mew=2)\n",
    "_ = plt.xlim(xx.min(), xx.max())\n",
    "_ = plt.ylim(-9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler2 = gpflow.train.HMC()\n",
    "samples2 = sampler2.sample(m2, num_samples=gpflow.test_util.notebook_niter(100000), epsilon=0.05,logprobs=False)#,era 0.005 lmin=10, lmax=20, logprobs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "for i, col in samples2.iteritems():\n",
    "    plt.plot(col, label=col.name)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('hmc iteration')\n",
    "plt.ylabel('parameter value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "axs[0].plot(samples2['GPR/likelihood/variance'],\n",
    "            samples2['GPR/kern/variance'], 'k.', alpha = 0.15)\n",
    "axs[0].set_xlabel('noise_variance')\n",
    "axs[0].set_ylabel('signal_variance')\n",
    "\n",
    "axs[1].plot(samples2['GPR/likelihood/variance'],\n",
    "            samples2['GPR/kern/lengthscales'], 'k.', alpha = 0.15)\n",
    "axs[1].set_xlabel('noise_variance')\n",
    "axs[1].set_ylabel('lengthscale')\n",
    "\n",
    "axs[2].plot(samples2['GPR/kern/lengthscales'],\n",
    "            samples2['GPR/kern/variance'], 'k.', alpha = 0.1)\n",
    "axs[2].set_xlabel('lengthscale')\n",
    "axs[2].set_ylabel('signal_variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot the function posterior\n",
    "xx = np.linspace(0, 6, 100)[:,None]\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, s in samples2.iloc[::20].iterrows():\n",
    "    f = m2.predict_f_samples(xx, 1, initialize=False, feed_dict=m2.sample_feed_dict(s))\n",
    "    plt.plot(xx, f[0,:,:], 'C0', lw=2, alpha=0.1)\n",
    "    \n",
    "plt.plot(t, x, 'kx', mew=2)\n",
    "_ = plt.xlim(xx.min(), xx.max())\n",
    "_ = plt.ylim(-9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gelman-Rubin Statistic calculated for the three parameters\n",
    "#first chain\n",
    "variance_vector=samples['GPR/kern/variance'].values# works works works !!!!\n",
    "lengthscales_vector=samples['GPR/kern/lengthscales'].values\n",
    "likelihood_variance_vector=samples['GPR/likelihood/variance'].values\n",
    "#second chain\n",
    "variance_vector1=samples1['GPR/kern/variance'].values# works works works !!!!\n",
    "lengthscales_vector1=samples1['GPR/kern/lengthscales'].values\n",
    "likelihood_variance_vector1=samples1['GPR/likelihood/variance'].values\n",
    "# third chain\n",
    "variance_vector2=samples2['GPR/kern/variance'].values# works works works !!!!\n",
    "lengthscales_vector2=samples2['GPR/kern/lengthscales'].values\n",
    "likelihood_variance_vector2=samples2['GPR/likelihood/variance'].values\n",
    "# create a list with all the three chains wrt each parameter in turn\n",
    "l_variance=[]\n",
    "l_lengthscales=[]\n",
    "l_likelihood_variance=[]\n",
    "# append the vectors\n",
    "#variance_vectors\n",
    "l_variance.append(variance_vector)\n",
    "l_variance.append(variance_vector1)\n",
    "l_variance.append(variance_vector2)\n",
    "#lengthscales_vectors\n",
    "l_lengthscales.append(lengthscales_vector)\n",
    "l_lengthscales.append(lengthscales_vector1)\n",
    "l_lengthscales.append(lengthscales_vector2)\n",
    "#likelihood_variance_vectors\n",
    "l_likelihood_variance.append(likelihood_variance_vector)\n",
    "l_likelihood_variance.append(likelihood_variance_vector1)\n",
    "l_likelihood_variance.append(likelihood_variance_vector2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x: data cell array\n",
    "# m: no of chains run\n",
    "# Within Chain Variance \n",
    "m=3\n",
    "ssq_variance = np.zeros(m)\n",
    "ssq_lengthscales=np.zeros(m)\n",
    "ssq_likelihood_variance=np.zeros(m)\n",
    "for j in range(0,m):\n",
    "    ssq_variance[j]=np.var(l_variance[j])\n",
    "for j in range(0,m):\n",
    "    ssq_lengthscales[j]=np.var(l_lengthscales[j])    \n",
    "for j in range(0,m):\n",
    "    ssq_likelihood_variance[j]=np.var(l_likelihood_variance[j])    \n",
    "        \n",
    "    \n",
    "Wvar_variance = np.mean(ssq_variance)\n",
    "Wvar_lengthscales=np.mean(ssq_lengthscales)\n",
    "Wvar_likelihood_variance=np.mean(ssq_likelihood_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Between Chain Variance\n",
    "schain_variance,schain_lengthscales,schain_likelihood_variance = 0,0,0\n",
    "chainlng_variance=len(l_variance[0])\n",
    "chainlng_lengthscales=len(l_lengthscales[0])\n",
    "chainlng_likelihood_variance=len(l_likelihood_variance[0])\n",
    "for j in range(0,m):\n",
    "    schain_variance = schain_variance + np.mean(l_variance[j]) # sum of all chain means\n",
    "    schain_lengthscales = schain_lengthscales + np.mean(l_lengthscales[j])\n",
    "    schain_likelihood_variance=schain_likelihood_variance+np.mean(l_likelihood_variance[j])\n",
    "\n",
    "mubar2_variance = (1/m)*schain_variance\n",
    "mubar2_lengthscales = (1/m)*schain_lengthscales\n",
    "mubar2_likelihood_variance = (1/m)*schain_likelihood_variance\n",
    "bs_variance,bs_lengthscales,bs_likelihood_variance=0,0,0\n",
    "\n",
    "for j in range(0,m):\n",
    "    bs_variance=bs_variance+(np.mean(l_variance[j])-mubar2_variance)**2\n",
    "    bs_lengthscales=bs_lengthscales+(np.mean(l_lengthscales[j])-mubar2_lengthscales)**2\n",
    "    bs_likelihood_variance=bs_likelihood_variance+np.mean(l_likelihood_variance[j]-mubar2_likelihood_variance )**2\n",
    "\n",
    "Bvar_variance = (chainlng_variance/(m-1))*bs_variance # all chains have the same length\n",
    "Bvar_lengthscales = (chainlng_lengthscales/(m-1))*bs_lengthscales\n",
    "Bvar_likelihood_variance = (chainlng_likelihood_variance/(m-1))*bs_likelihood_variance\n",
    "\n",
    "# Estimated variance\n",
    "muvar_variance = (1-1/chainlng_variance)*Wvar_variance + (1/chainlng_variance)*Bvar_variance\n",
    "muvar_lengthscales = (1-1/chainlng_lengthscales)*Wvar_lengthscales+ (1/chainlng_lengthscales)*Bvar_lengthscales\n",
    "muvar_likelihood_variance = (1-1/chainlng_likelihood_variance)*Wvar_likelihood_variance + (1/chainlng_likelihood_variance)*Bvar_likelihood_variance\n",
    "\n",
    "# Potential Scale Reduction Factor\n",
    "R_variance = np.sqrt(muvar_variance/Wvar_variance)\n",
    "R_lengthscales = np.sqrt(muvar_lengthscales/Wvar_lengthscales) \n",
    "R_likelihood_variance = np.sqrt(muvar_likelihood_variance/Wvar_likelihood_variance) \n",
    "\n",
    "print(R_variance)\n",
    "print(R_lengthscales)# smaller than 1.1, so the chain has converged.\n",
    "print(R_likelihood_variance)# smaller than 1.1, so the chain has converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
