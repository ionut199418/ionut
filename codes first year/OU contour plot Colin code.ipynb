{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import decimal\n",
    "import scipy.linalg\n",
    "import numpy.random as nrand\n",
    "import matplotlib.pyplot as plt\n",
    "import gpflow\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 6)\n",
    "plt = matplotlib.pyplot\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel, ConstantKernel, Matern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ou_levels(a,b,dt,sigma,time):\n",
    "    #This method returns the rate levels of a mean-reverting ornstein uhlenbeck process.\n",
    "    x = np.zeros(len(time))\n",
    "    for i in range(0, len(time)-1):\n",
    "        x[i+1]=x[i]+a*(b-x[i])*dt+math.sqrt(dt)*sigma*np.random.normal(0,1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OU data\n",
    "# get OU data first\n",
    "dt=0.02\n",
    "time=np.arange(0,50,dt)# time\n",
    "sigma=1\n",
    "a=1# the coefficient in front, the rate\n",
    "b=0# the mean\n",
    "training_data=ou_levels(a,b,dt,sigma,time)\n",
    "#t=time# time vector\n",
    "#x=training_data\n",
    "#t=t[::8]\n",
    "#x=x[::8]\n",
    "#t_column=t.reshape(-1,1)\n",
    "#x_column=x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the code\n",
    "X=time.reshape(-1,1)\n",
    "y=training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X,y)\n",
    "plt.title('OU process')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run\n",
    "plt.figure(0)\n",
    "kernel = ConstantKernel(1.0) * Matern(length_scale=1.0,nu=0.5) \\\n",
    "    + WhiteKernel(noise_level=1)\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=0.0).fit(X, y)\n",
    "#X_ = np.linspace(0, 5, 100)# watch it here, old code\n",
    "dt=0.05\n",
    "X_=np.arange(0,40,dt)\n",
    "y_mean, y_cov = gp.predict(X_[:, np.newaxis], return_cov=True)\n",
    "plt.plot(X_, y_mean, 'k', lw=3, zorder=9)\n",
    "plt.fill_between(X_, y_mean - np.sqrt(np.diag(y_cov)),\n",
    "                 y_mean + np.sqrt(np.diag(y_cov)),\n",
    "                 alpha=0.5, color='k')\n",
    "# time_=X_\n",
    "# y_=ou_levels(a,b,dt,sigma,time)\n",
    "# plt.plot(X_, y_, 'r', lw=3, zorder=9)# this is what I think about, ou_levels(a,b,dt,sigma,time)\n",
    "# plt.scatter(X[:, 0], y, c='r', s=50, zorder=10, edgecolors=(0, 0, 0))\n",
    "plt.title(\"Initial: %s\\nOptimum: %s\\nLog-Marginal-Likelihood: %s\"\n",
    "           % (kernel, gp.kernel_,\n",
    "              gp.log_marginal_likelihood(gp.kernel_.theta)))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = np.linspace(1e-4, 1, 40)\n",
    "theta1 = np.linspace(1e-4, 2, 40)\n",
    "Theta0, Theta1 = np.meshgrid(theta0, theta1)\n",
    "LML = [[gp.log_marginal_likelihood([np.log(Theta0[i, j]), np.log(Theta1[i, j]),gp.kernel_.theta[2]])# here is the key that 0.70 that is the function variance\n",
    "        for i in range(Theta0.shape[0])] for j in range(Theta0.shape[1])]\n",
    "LML = np.array(LML).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.ylabel(\"Length-scale\")\n",
    "plt.xlabel(\"Noise-level\")\n",
    "plt.title(\"Log-marginal-likelihood\")\n",
    "plt.tight_layout()\n",
    "#plt.axis('equal')\n",
    "plt.pcolor(Theta0, Theta1, LML,vmin=1200,vmax=1320)\n",
    "plt.colorbar()\n",
    "plt.plot(0.5, 1, 'ko', zorder=10,label='true')\n",
    "plt.plot(np.exp(gp.kernel_.theta[0]), np.exp(gp.kernel_.theta[1]), 'ro', zorder=10,label='optimized')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "level = np.linspace(0, 1315, 100)#, decimals=1)\n",
    "plt.contour(Theta0, Theta1, LML,levels=level)#,norm=LogNorm(vmin=50, vmax=100))\n",
    "plt.colorbar()\n",
    "plt.plot(0.5, 1, 'ko', zorder=10,label='true')\n",
    "plt.plot(np.exp(gp.kernel_.theta[0]), np.exp(gp.kernel_.theta[1]), 'ro', zorder=10,label='optimized')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.axis([0.05,1,0.05,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
