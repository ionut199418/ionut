{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function R = GelmanRubinR(x, m, chainlng, dim)\n",
    "# Calculates scale reduction factor for Gelman Rubin test\n",
    "# Input parameters:\n",
    "# x: data cell array\n",
    "# m: no of chains run\n",
    "# chainlng: chain length\n",
    "# dim: indicates for which parameter in the cell array R will be calculated\n",
    "#\n",
    "# Output parameters\n",
    "# R: scale reduction factor\n",
    "\n",
    "# Within Chain Variance\n",
    "#ssq = NaN(m, 1);\n",
    "#for j = 1:m\n",
    " #   ssq(j) = var(x{j}(dim,:)); \n",
    "#end\n",
    "#Wvar = mean(ssq); %or Wvar = (1/m)*sum(ssq);\n",
    "\n",
    "#% Between Chain Variance\n",
    "#schain = 0;\n",
    "#for j = 1:m\n",
    " #   schain = schain + mean(x{j}(dim,:)); % sum of all chain means\n",
    "#end\n",
    "\n",
    "#mubar2 = (1/m)*schain;\n",
    "\n",
    "#bs = 0;\n",
    "#for j = 1:m\n",
    " #   bs = bs + sum((mean(x{j}(dim,:))-mubar2)^2);\n",
    "#end\n",
    "#Bvar = (chainlng/(m-1))*bs;\n",
    "\n",
    "#% Estimated variance\n",
    "#muvar = (1-1/chainlng)*Wvar + (1/chainlng)*Bvar;\n",
    "\n",
    "#% Potential Scale Reduction Factor\n",
    "#R = sqrt(muvar/Wvar); \n",
    "\n",
    "#end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import statistics\n",
    "import scipy.stats as stats\n",
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from scipy.stats import binom\n",
    "%matplotlib inline\n",
    "%precision 4\n",
    "plt.style.use('ggplot')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import beta\n",
    "from functools import partial\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rw2(n):# this gives samples from weibull(5,2)# put n=10000,the shape 5 and the scale 2\n",
    "    x,y=0,0\n",
    "    distance=[]\n",
    "    for i in range(1,n+1):\n",
    "            r=random.weibullvariate(alpha,beta) # step size r\n",
    "            theta=2.*math.pi*random.random()\n",
    "            x +=r*math.cos(theta)\n",
    "            y +=r*math.sin(theta)\n",
    "            distance.append(r)# save the distances r for the mcmc sampler\n",
    "    return(np.array(distance))# depending what do you want to do, either save the pairs, or save the distances r  between points\n",
    "    #return(x,y)\n",
    "    \n",
    "alpha=2#float(input(\"what's the scale?\"))\n",
    "beta=5#float(input(\"what's the shape?\"))\n",
    "n=10000#int(input(\"how many steps?\"))\n",
    "#tries=int(input(\"how many tries?\"))#  put tries=1  in order to properly save the list distance\n",
    "data = rw2(n)# very important because you need the same data, if you put rw2(n) in there you change the data every time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the log likelihood of weibull(a,b)\n",
    "import scipy.stats \n",
    "from scipy.stats import dweibull\n",
    "def log_likelihood(x,a,b):\n",
    "     return sum(dweibull.logpdf(x,scale=b,c=a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-e28cc0d4b3c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Acceptance rate = \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccepted\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10000.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "#n=10000 #number of observations in a sample \n",
    "# initial guess for theta(a and b) as array.\n",
    "def mh(guess):\n",
    "    #guess = [5.0,2.0]\n",
    "# Prepare storing MCMC chain as array of arrays.\n",
    "    A = [guess]\n",
    "    # define stepsize of MCMC.\n",
    "    stepsizes = [0.01,0.01]  # array of stepsizes\n",
    "    accepted  = 0.0\n",
    "    old_theta=guess# define initial values for theta \n",
    "    old_loglik = log_likelihood(data,old_theta[0],old_theta[1])#calculate the first log likelihood\n",
    "# Metropolis-Hastings with 10,000 iterations.\n",
    "    for p in range(10000):\n",
    "    #old_theta  = A[len(A)-1]   old parameter value as array(not that elegant way)\n",
    "    # Suggest new candidate from Gaussian proposal distribution.\n",
    "    #new_theta = np.zeros([len(old_theta)])\n",
    "        new_theta = old_theta + stats.norm(0, stepsizes).rvs() \n",
    "    #add the restraints on new_theta\n",
    "        if new_theta[0]<0 or new_theta[1]<0: \n",
    "            continue\n",
    "        new_loglik = log_likelihood(data,new_theta[0],new_theta[1])\n",
    "    # Accept new candidate in Monte-Carlo fashing.\n",
    "        if (new_loglik > old_loglik):\n",
    "            A.append(new_theta)\n",
    "            accepted = accepted + 1.0  # monitor acceptance\n",
    "            old_loglik=new_loglik\n",
    "            old_theta=new_theta\n",
    "        else:\n",
    "            u = random.uniform(0.0,1.0)\n",
    "            if (u < math.exp(new_loglik - old_loglik)):\n",
    "                A.append(new_theta)\n",
    "                accepted = accepted + 1.0  # monitor acceptance\n",
    "                old_loglik=new_loglik\n",
    "                old_theta=new_theta\n",
    "            else:\n",
    "                A.append(old_theta)\n",
    "    print(\"Acceptance rate = \"+str(accepted/10000.0))\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate = 0.4256\n",
      "Acceptance rate = 0.4113\n",
      "Acceptance rate = 0.4137\n",
      "Acceptance rate = 0.4164\n",
      "Acceptance rate = 0.4204\n"
     ]
    }
   ],
   "source": [
    "sampless_shape = [mh([theta,2]) for theta in np.linspace(2,7,5)]# 5 mh chains for shape keeping the scale fixed at 2 and varying \n",
    "# the starting points for the shape from 2 to 7                 # should consider replacing 5 with a letter determining the number of chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate = 0.4176\n",
      "Acceptance rate = 0.4174\n",
      "Acceptance rate = 0.4256\n",
      "Acceptance rate = 0.419\n",
      "Acceptance rate = 0.4205\n"
     ]
    }
   ],
   "source": [
    "sampless_scale=[mh([5,theta]) for theta in np.linspace(1,6,5)]# see above\n",
    "#5 mh chains for scale keeping the shape fixed at 5 and varying the starting points from 1 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sampless_shape\n",
    "final_shape_vector=[[p[0] for p in chain] for chain in sampless_shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_scale_vector=[[p[1] for p in chain] for chain in sampless_scale]\n",
    "#final_scale_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x: data cell array\n",
    "# m: no of chains run\n",
    "# Within Chain Variance \n",
    "m=5\n",
    "ssq_shape = np.zeros(m)\n",
    "ssq_scale=np.zeros(m)\n",
    "for j in range(0,m):\n",
    "    ssq_shape[j]=np.var(final_shape_vector[j])\n",
    "for j in range(0,m):\n",
    "    ssq_scale[j]=np.var(final_scale_vector[j])    \n",
    "    \n",
    "Wvar_shape = np.mean(ssq_shape)\n",
    "Wvar_scale=np.mean(ssq_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03209869705\n",
      "1.03292147314\n"
     ]
    }
   ],
   "source": [
    "# Between Chain Variance\n",
    "schain_shape,schain_scale = 0,0\n",
    "chainlng_shape=len(final_shape_vector[0])\n",
    "chainlng_scale=len(final_scale_vector[0])\n",
    "for j in range(0,m):\n",
    "    schain_shape = schain_shape + np.mean(final_shape_vector[j]) # sum of all chain means\n",
    "    schain_scale = schain_scale + np.mean(final_scale_vector[j])\n",
    "\n",
    "mubar2_shape = (1/m)*schain_shape\n",
    "mubar2_scale = (1/m)*schain_scale\n",
    "bs_shape,bs_scale=0,0\n",
    "for j in range(0,m):\n",
    "    bs_shape=bs_shape+(np.mean(final_shape_vector[j])-mubar2_shape)**2\n",
    "    bs_scale=bs_scale+(np.mean(final_scale_vector[j])-mubar2_scale)**2\n",
    "Bvar_shape = (chainlng_shape/(m-1))*bs_shape # all chains have the same length\n",
    "Bvar_scale = (chainlng_scale/(m-1))*bs_scale\n",
    "# Estimated variance\n",
    "muvar_shape = (1-1/chainlng_shape)*Wvar_shape + (1/chainlng_shape)*Bvar_shape\n",
    "muvar_scale = (1-1/chainlng_scale)*Wvar_scale + (1/chainlng_scale)*Bvar_scale\n",
    "\n",
    "# Potential Scale Reduction Factor\n",
    "R_shape = np.sqrt(muvar_shape/Wvar_shape)\n",
    "R_scale = np.sqrt(muvar_scale/Wvar_scale) \n",
    "\n",
    "print(R_shape)\n",
    "print(R_scale)# smaller than 1.1, so the chain has converged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
